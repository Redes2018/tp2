{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/usr/local/lib/python3.5/site-packages')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "carpeta = (os.getcwd()+'/tc02Data/')\n",
    "\n",
    "# Nombres de los archivos: yeast_(...).txt\n",
    "archivos = ['Y2H','AP-MS','LIT','LIT_Reguly']\n",
    "\n",
    "# Lista donde se van a ir agregando los grafos en el orden de los archivos\n",
    "Gs = []\n",
    "\n",
    "for j,archivo in enumerate(archivos):\n",
    "    data = pd.read_csv(carpeta+'yeast_'+archivo+'.txt', sep='\\t', header=None)\n",
    "    \n",
    "    G = nx.Graph()\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        G.add_edges_from([(data[0][i],data[1][i])])\n",
    "    Gs.append(G)\n",
    "\n",
    "# El último archivo, LIT_Reguly, es el único que tiene encabezado\n",
    "# Quise poner header automático pero devuelve un error, así que elimino lo que sobra a lo bruto\n",
    "Gs[3].remove_node(\"Bait gene/protein\")\n",
    "Gs[3].remove_node(\"Hit gene/protein\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Luli\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Proteinas esenciales\n",
    "data_ess = pd.read_csv(carpeta+'Essential_ORFs_paperHe.txt', sep='\\t', header=0,skipfooter=4,usecols=[1])\n",
    "\n",
    "# Para eliminar los espacios en los nombres de las proteinas\n",
    "data_ess['ORF_name'] = data_ess['ORF_name'].map(lambda x: x.strip())\n",
    "\n",
    "ess = data_ess[\"ORF_name\"].tolist()\n",
    "del ess[0] # como antes, elimino el encabezado\n",
    "\n",
    "# ess es la lista de proteinas esenciales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Agrego la caracteristica de ser o no esencial\n",
    "\n",
    "for G in Gs:\n",
    "    nodos_G = set(G.nodes()) # set de nodos de G\n",
    "    nodos_ess_G = nodos_G.intersection(set(ess)) # nodos esenciales de G (como interseccion entre nodos de G y esenciales)\n",
    "    nodos_no_ess_G = nodos_G.difference(set(ess)) # nodos no esenciales de G (como diferencia entre nodos de G y esenciales)\n",
    "    \n",
    "    # Agrego el atributo correspondiente a cada nodo\n",
    "    G.add_nodes_from(nodos_ess_G, essential=True)\n",
    "    G.add_nodes_from(nodos_no_ess_G, essential=False)\n",
    "\n",
    "# Para comprobarlo me fije que la cantidad de nodos sea la misma antes y despues de esto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Alfa y beta calculados en los ajustes lineales\n",
    "alpha = [0.0162, 0.0468, 0.0815, 0.0456]\n",
    "beta = [0.1722, 0.181, 0.2437, 0.0733]\n",
    "err_alpha = [0.0095, 0.0121, 0.0154, 0.0024]\n",
    "err_beta = [0.0678, 0.1187, 0.0862, 0.0252]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Para calcular los nodos del mismo tipo según el modelo lineal, usamos los alfa y beta calculados\n",
    "# y además defino una probabilidad que depende del grado del nodo (k) y de la red (i)\n",
    "def Pe(k,i):\n",
    "    Pe = 1 - (1-beta[i]) * (1-alpha[i])**k\n",
    "    err_Pe = np.sqrt( (1-alpha[i])**(2*k) * err_beta[i]**2 + (1-beta[i])**2 + k**2 * (1-alpha[i])**(2*(k-1)) * err_alpha[i]**2 )\n",
    "    return (Pe, err_Pe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[522, 11613, 730, 10777]\n",
      "[352, 5907, 389, 6187]\n",
      "[290, 7482, 396, 5660]\n",
      "[11.594464790910704, 83.887685896795958, 11.435218862365005, 64.259100095426774]\n"
     ]
    }
   ],
   "source": [
    "pairs_total = []\n",
    "pairs_sametype = []\n",
    "pairs_exp = []\n",
    "pairs_exp_err = []\n",
    "\n",
    "for n,G in enumerate(Gs):\n",
    "    nodos_lista = list(G.nodes())\n",
    "    grados_dict = dict(G.degree())\n",
    "    ess_dict = nx.get_node_attributes(G,'essential')\n",
    "\n",
    "    A = nx.to_numpy_matrix(G) # matriz de adyacencia de G\n",
    "    T = len(A) # tamaño de la matriz, debe ser igual que la cantidad de nodos, me aseguro:\n",
    "\n",
    "    if G.number_of_nodes()!=T:\n",
    "        print('El grafo y la matriz no son del mismo tamaño')\n",
    "\n",
    "    for i in range(T):\n",
    "        A[i,i]=0 # Como hay auto loops, pongo ceros en la diagonal\n",
    "\n",
    "    # Creo la matriz de adyacencia al cuadrado\n",
    "    A2 = A**2\n",
    "    # El lugar i,j de esta matriz me dice cuantos caminos de longitud 2 hay entre el nodo i y el j\n",
    "\n",
    "    # Como quiero quedarme con pares de nodos que tengan al menos 3 vecinos en común,\n",
    "    # busco que haya al menos 3 caminos de longitud 2 entre ellos\n",
    "    I,J = np.where(A2 >= 3)\n",
    "    # obtengo los indices de los lugares\n",
    "    \n",
    "    # Cuento cantidad de pares de nodos con 3 o más vecinos en común\n",
    "    pares = 0\n",
    "    pares_iguales = 0\n",
    "    N_exp = 0\n",
    "    errPisquared = 0\n",
    "\n",
    "    for i in range(len(I)):\n",
    "        if I[i]!=J[i] and A[I[i],J[i]] == 0:\n",
    "            pares +=1\n",
    "            nodo1 = nodos_lista[I[i]]\n",
    "            nodo2 = nodos_lista[J[i]]\n",
    "            Pe1, errPe1 = Pe(grados_dict[nodo1],n)\n",
    "            Pe2, errPe2 = Pe(grados_dict[nodo2],n)\n",
    "            P1 = Pe1 * Pe2 + (1-Pe1) * (1-Pe2)\n",
    "            errP1squared = ((2*Pe1-1)*errPe1)**2 + ((2*Pe2-1)*errPe2)**2\n",
    "            errPisquared = errPisquared + errP1squared\n",
    "            N_exp = N_exp + P1\n",
    "            if ess_dict[nodo1] == ess_dict[nodo2]:\n",
    "                pares_iguales +=1\n",
    "    pares = int(pares/2)\n",
    "    pares_iguales = int(pares_iguales/2)\n",
    "    N_exp = int(N_exp/2)\n",
    "    N_err = np.sqrt(errPisquared/2)\n",
    "\n",
    "    pairs_total.append(pares)\n",
    "    pairs_sametype.append(pares_iguales)\n",
    "    pairs_exp.append(N_exp)\n",
    "    pairs_exp_err.append(N_err)\n",
    "\n",
    "print(pairs_total)\n",
    "print(pairs_sametype)\n",
    "print(pairs_exp)\n",
    "print(pairs_exp_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23073\n",
      "15087\n",
      "13693\n",
      "112.543088712\n"
     ]
    }
   ],
   "source": [
    "# Para el caso de Y2H hay que considerar los pares que tengan al menos 1 vecino en común\n",
    "G=Gs[0]\n",
    "nodos_lista = list(G.nodes())\n",
    "grados_dict = dict(G.degree())\n",
    "ess_dict = nx.get_node_attributes(G,'essential')\n",
    "\n",
    "A = nx.to_numpy_matrix(G) # matriz de adyacencia de G\n",
    "T = len(A) # tamaño de la matriz, debe ser igual que la cantidad de nodos, me aseguro:\n",
    "\n",
    "if G.number_of_nodes()!=T:\n",
    "    print('El grafo y la matriz no son del mismo tamaño')\n",
    "\n",
    "for i in range(T):\n",
    "    A[i,i]=0 # Como hay auto loops, pongo ceros en la diagonal\n",
    "\n",
    "# Creo la matriz de adyacencia al cuadrado\n",
    "A2 = A**2\n",
    "# El lugar i,j de esta matriz me dice cuantos caminos de longitud 2 hay entre el nodo i y el j\n",
    "\n",
    "# Como quiero quedarme con pares de nodos que tengan al menos 1 vecino en común,\n",
    "# busco que haya al menos 1 camino de longitud 2 entre ellos\n",
    "I,J = np.where(A2 >= 1)\n",
    "# obtengo los indices de los lugares\n",
    "\n",
    "# Cuento cantidad de pares de nodos con 3 o más vecinos en común\n",
    "pares = 0\n",
    "pares_iguales = 0\n",
    "N_exp = 0\n",
    "errPisquared = 0\n",
    "\n",
    "for i in range(len(I)):\n",
    "    if I[i]!=J[i] and A[I[i],J[i]] == 0:\n",
    "        pares +=1\n",
    "        nodo1 = nodos_lista[I[i]]\n",
    "        nodo2 = nodos_lista[J[i]]\n",
    "        Pe1, errPe1 = Pe(grados_dict[nodo1],n)\n",
    "        Pe2, errPe2 = Pe(grados_dict[nodo2],n)\n",
    "        P1 = Pe1 * Pe2 + (1-Pe1) * (1-Pe2)\n",
    "        errP1squared = ((2*Pe1-1)*errPe1)**2 + ((2*Pe2-1)*errPe2)**2\n",
    "        errPisquared = errPisquared + errP1squared\n",
    "        N_exp = N_exp + P1\n",
    "        if ess_dict[nodo1] == ess_dict[nodo2]:\n",
    "            pares_iguales +=1\n",
    "pares = int(pares/2)\n",
    "pares_iguales = int(pares_iguales/2)\n",
    "N_exp = int(N_exp/2)\n",
    "N_err = np.sqrt(errPisquared/2)\n",
    "\n",
    "print(pares)\n",
    "print(pares_iguales)\n",
    "print(N_exp)\n",
    "print(N_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
