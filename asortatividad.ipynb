{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/usr/local/lib/python3.5/site-packages')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "carpeta = (os.getcwd()+'/tc02Data/')\n",
    "\n",
    "# Nombres de los archivos: yeast_(...).txt\n",
    "archivos = ['Y2H','AP-MS','LIT','LIT_Reguly']\n",
    "\n",
    "# Lista donde se van a ir agregando los grafos en el orden de los archivos\n",
    "Gs = []\n",
    "\n",
    "for j,archivo in enumerate(archivos):\n",
    "    data = pd.read_csv(carpeta+'yeast_'+archivo+'.txt', sep='\\t', header=None)\n",
    "    \n",
    "    G = nx.Graph()\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        G.add_edges_from([(data[0][i],data[1][i])])\n",
    "    Gs.append(G)\n",
    "\n",
    "# El último archivo, LIT_Reguly, es el único que tiene encabezado\n",
    "# Quise poner header automático pero devuelve un error, así que elimino lo que sobra a lo bruto\n",
    "Gs[3].remove_node(\"Bait gene/protein\")\n",
    "Gs[3].remove_node(\"Hit gene/protein\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Luli\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Proteinas esenciales\n",
    "data_ess = pd.read_csv(carpeta+'Essential_ORFs_paperHe.txt', sep='\\t', header=0,skipfooter=4,usecols=[1])\n",
    "\n",
    "# Para eliminar los espacios en los nombres de las proteinas\n",
    "data_ess['ORF_name'] = data_ess['ORF_name'].map(lambda x: x.strip())\n",
    "\n",
    "ess = data_ess[\"ORF_name\"].tolist()\n",
    "del ess[0] # como antes, elimino el encabezado\n",
    "\n",
    "# ess es la lista de proteinas esenciales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Agrego la caracteristica de ser o no esencial\n",
    "from funciones import esenciales\n",
    "\n",
    "for G in Gs:\n",
    "    esenciales(G,ess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G = Gs[0]\n",
    "\n",
    "Enlaces_iguales = [] # Lista donde se almacenan la cantidad de enlaces entre proteínas del mismo tipo\n",
    "\n",
    "N_iter = 2000\n",
    "\n",
    "nodos_lista = list(G.nodes())\n",
    "ess_dict = nx.get_node_attributes(G,'essential')\n",
    "ess_lista = list(ess_dict)\n",
    "\n",
    "\n",
    "for it in range(N_iter):\n",
    "    ess_shuffle = ess_lista\n",
    "    np.random.shuffle(ess_shuffle) # Reordenamos aleat los generos para el resto de las iteraciones\n",
    "\n",
    "    # Reasignamos a cada nodo un valor de esencialidad del vector de ess_shuffle:\n",
    "    for nodo,esen in zip(nodos_lista,ess_shuffle):\n",
    "        G.add_node(nodo, essential=esen)\n",
    "        \n",
    "    #Cuenta la fraccion de enlaces que conecta nodos de igual tipo:\n",
    "    enlaces = list(G.edges.data())\n",
    "    enlaces_igual = 0 # Ponemos en cero el contador de enlaces iguales\n",
    "\n",
    "    # Recorremos los enlaces y nos fijamos cual de ellos es entre iguales:\n",
    "    for i in range(0,len(enlaces)-1):\n",
    "        esencialidad1 = G.nodes[enlaces[i][0]]['essential']\n",
    "        esencialidad2 = G.nodes[enlaces[i][1]]['essential']\n",
    "        if esencialidad1 == esencialidad2:   # Comparamos los tipos\n",
    "            enlaces_igual += 1 # Incrementamos el contador si los tipos son iguales\n",
    "    Enlaces_iguales.append(enlaces_igual) # Guardamos la cantidad de enlaces del mismo tipo en cada iteración\n",
    "\n",
    "# Ahora tenemos una lista Enlaces_iguales con la cantidad de enlaces iguales para N iteraciones\n",
    "\n",
    "# Valor medio y desviacion standar\n",
    "mean_enlaces = np.mean(Enlaces_iguales)\n",
    "desv_enlaces = np.std(Enlaces_iguales)\n",
    "\n",
    "print ('Distribucion de enlaces del mismo tipo:')\n",
    "print ('Valor medio(H null): {0:.2f}'.format(mean_enlaces))\n",
    "print ('Desviacion Standar: {0:.2f}'.format(desv_enlaces))\n",
    "#print ('Valor Red Real: {0:.2f}'.format(Enlaces_iguales[0])) #CAMBIAR ESTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.07216729,  0.3463515 ,  0.3093429 ,  0.20568567])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = len(Gs)\n",
    "Q = np.zeros(L)\n",
    "\n",
    "for i, G in enumerate(Gs):\n",
    "    N = G.number_of_nodes()\n",
    "    m = G.number_of_edges()\n",
    "    proteinas = list(G.nodes())\n",
    "    grado = dict(G.degree())\n",
    "    A = nx.to_numpy_matrix(G)\n",
    "\n",
    "    # Matriz de variable categorica esencialidad: Cij=delta(ci,cj)\n",
    "    C = np.zeros(np.shape(A))\n",
    "\n",
    "    for ni, inodo in enumerate(proteinas):\n",
    "        for nj, jnodo in enumerate(proteinas):\n",
    "            if G.nodes[inodo]['essential']==G.nodes[jnodo]['essential']:\n",
    "                C[ni,nj] = 1\n",
    "\n",
    "    #Calculo de la modularidad\n",
    "    #Q/Qmax=(S1-S2)/(2m-S2)\n",
    "\n",
    "    #S1=Suma en nodos (Aij*Cij)\n",
    "    #S2=Suma en nodos(kikj*Cij/2m)\n",
    "    S1 = 0\n",
    "    S2 = 0\n",
    "    for ni, inodo in enumerate(proteinas):\n",
    "        for nj, jnodo in enumerate(proteinas):  \n",
    "            S1 = S1 + A[ni,nj]*C[ni,nj]\n",
    "            S2 = S2 + grado[inodo]*grado[jnodo]*C[ni,nj]\n",
    "    S2 = S2/(2*m)\n",
    "    Q[i] = (S1-S2)/(2*m-S2)\n",
    "    \n",
    "Q\n",
    "    \n",
    "#  Si da un valor positivo entre 0 y 1, hay más enlaces entre nodos con igual esencialidad que los esperados por azar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
