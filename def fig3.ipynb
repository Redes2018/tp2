{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/usr/local/lib/python3.5/site-packages')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import os\n",
    "import random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "carpeta = (os.getcwd()+'/tc02Data/')\n",
    "\n",
    "# Nombres de los archivos: yeast_(...).txt\n",
    "archivos = ['Y2H','AP-MS','LIT','LIT_Reguly']\n",
    "\n",
    "# Lista donde se van a ir agregando los grafos en el orden de los archivos\n",
    "Gs = []\n",
    "\n",
    "for j,archivo in enumerate(archivos):\n",
    "    data = pd.read_csv(carpeta+'yeast_'+archivo+'.txt', sep='\\t', header=None)\n",
    "    \n",
    "    G = nx.Graph()\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        G.add_edges_from([(data[0][i],data[1][i])])\n",
    "    Gs.append(G)\n",
    "\n",
    "# El último archivo, LIT_Reguly, es el único que tiene encabezado\n",
    "# Quise poner header automático pero devuelve un error, así que elimino lo que sobra a lo bruto\n",
    "Gs[3].remove_node(\"Bait gene/protein\")\n",
    "Gs[3].remove_node(\"Hit gene/protein\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lucio\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Proteinas esenciales\n",
    "data_ess = pd.read_csv(carpeta+'Essential_ORFs_paperHe.txt', sep='\\t', header=0,skipfooter=4,usecols=[1])\n",
    "\n",
    "# Para eliminar los espacios en los nombres de las proteinas\n",
    "data_ess['ORF_name'] = data_ess['ORF_name'].map(lambda x: x.strip())\n",
    "\n",
    "ess = data_ess[\"ORF_name\"].tolist()\n",
    "del ess[0] # como antes, elimino el encabezado\n",
    "\n",
    "# ess es la lista de proteinas esenciales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fig3(G,ess,name):      \n",
    "    \n",
    "    #Creo copias superficiales de G porque solo me interesan sus nodos\n",
    "    G_copy0 = G.copy()\n",
    "    G_copy1 = G.copy()\n",
    "    G_copy2 = G.copy()\n",
    "    G_copy3 = G.copy()\n",
    "    G_copy4 = G.copy()\n",
    "    \n",
    "    \n",
    "    L = len(G) # tamaño del grafo (cantidad de nodos)\n",
    "    nodos_elim = np.arange(L) # vector que va del 0 al L-1, cantidad de nodos que se va a ir eliminando (eje x)\n",
    "    forn= nodos_elim/L #fracción de nodos eliminados\n",
    "        \n",
    "    lcc_dc= np.ones(L)#componente gigante obtenida mediante remoción de nodos por degree centrality (eje y)\n",
    "    lcc_dc[0] = L # la primera componente es el tamaño original del grafo\n",
    "\n",
    "    lcc_random= np.ones(L) #componente gigante obtenida mediante remocion de nodos aleatorios (eje y)\n",
    "    lcc_random[0] = L # la primera componente es el tamaño original del grafo\n",
    "    \n",
    "    lcc_ess= np.ones(L) #componente gigante obtenida mediante remoción de nodos esenciales de mayor a menor \"esencialidad\" (eje y)\n",
    "    lcc_ess[0] = L # la primera componente es el tamaño original del grafo\n",
    "    \n",
    "    \n",
    "    #Le voy sacando nodos de forma aleatoria. Defino una lista de los nodos de G y la mezlco\n",
    "    ls_r = list(G.nodes())\n",
    "    random.shuffle(ls_r) #ls_r ya queda mezclada\n",
    "    for i in range(L-1):\n",
    "        G_copy0.remove_node(ls_r[i])\n",
    "        lcc_random[i+1] = len(max(nx.connected_component_subgraphs(G_copy0),key=len))\n",
    "        \n",
    "    lcc_random = [ x/L for x in lcc_random]    \n",
    "\n",
    "        \n",
    "    #Le voy sacando nodos siguiendo de mayor a menor degree centrality y los ordeno\n",
    "    ls_dc=nx.degree_centrality(G_copy1)\n",
    "    ls_dc=sorted(ls_dc, key=ls_dc.__getitem__, reverse=True)  #Ordeno de menor a mayor, por eso revierto\n",
    "    for i in range(L-1):\n",
    "        G_copy1.remove_node(ls_dc[i])\n",
    "        lcc_dc[i+1] = len(max(nx.connected_component_subgraphs(G_copy1),key=len))\n",
    "    \n",
    "    lcc_dc = [ x/L for x in lcc_dc]    \n",
    "    \n",
    "    #Le saco todas las esenciales de una\n",
    "    from funciones import esenciales\n",
    "    (G,ls_ess,lista_no_es) = esenciales(G_copy2,ess) #uso esta funcion para obtener las lista de las ess en G\n",
    "    G_copy2.remove_nodes_from(ls_ess) #Le saco todos los esenciales\n",
    "    lcc_ess = len(max(nx.connected_component_subgraphs(G_copy2),key=len))/L\n",
    "    x=(len(ls_ess))/L  #defino mi x como la cant de nodos ess sacados/total\n",
    "    \n",
    "    from funciones import ec\n",
    "    (forn_ec,lcc_ec) = ec(G_copy3, ess)\n",
    "    \n",
    "    from funciones import spbc\n",
    "    (forn_spbc, lcc_spbc) = spbc(G_copy4, ess)\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    #Guardamos los datos:\n",
    "    output={}\n",
    "    output[name+'fron_random']=forn\n",
    "    output[name+'lcc_random']=lcc_random\n",
    "    \n",
    "    output[name+'forn_dc']=forn\n",
    "    output[name+'lcc_dc']=lcc_dc\n",
    "    \n",
    "    output[name+'lcc_ess']=lcc_ess\n",
    "    output[name+'forn_ess']= x\n",
    "    \n",
    "    output[name+'fron_ec']=forn_ec\n",
    "    output[name+'lcc_ec']=lcc_ec\n",
    "    \n",
    "    output[name+'fron_spbc']=forn_spbc\n",
    "    output[name+'lcc_spbc']=lcc_spbc\n",
    "  \n",
    "    \n",
    "    df= pd.DataFrame()\n",
    "    df['Date'] = output.keys()\n",
    "    df['DateValue'] = output.values()\n",
    "    df.to_csv(name+'_datos.txt', sep='\\t')\n",
    "    \n",
    "    plt.figure()\n",
    "\n",
    "    plt.plot(forn,lcc_random,'--r',label='Random')\n",
    "    plt.plot(forn,lcc_dc,'--m',label='DC')\n",
    "    plt.plot(x,lcc_ess,'b.',markersize=\"10\",label='Ess')\n",
    "    plt.plot(forn_ec,lcc_ec,'--c',label='EC')\n",
    "    plt.plot(forn_spbc,lcc_spbc,'--k',label='SPBC')\n",
    "\n",
    "    plt.xlabel('Cantidad de nodos eliminados')\n",
    "    plt.ylabel('Tamano de la componente gigante')\n",
    "    plt.title('Eliminacion de nodos segun distintas estrategias')\n",
    "    plt.legend()\n",
    "    plt.title(name)\n",
    "    plt.savefig(name+'_grafico.png')\n",
    "    plt.show()\n",
    "    \n",
    "    return(lcc_dc, lcc_random, lcc_ess, lcc_spbc, lcc_ec, forn, x)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nombres a poner son: ['Y2H','AP-MS','LIT','LIT_Reguly']\n",
    "G=Gs[0]\n",
    "H=Gs[1]\n",
    "I=Gs[2]\n",
    "J=Gs[3]\n",
    "\n",
    "fig3(G,ess,'Y2H')\n",
    "fig3(H,ess,'AP-MS')\n",
    "fig3(I,ess,'LIT')\n",
    "fig3(J,ess,'LIT_Reguly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
